# Продвинутые стратегии Prompt Engineering

## Введение

Данная заметка описывает продвинутые техники промпт-инжиниринга, которые позволяют более эффективно управлять поведением языковых моделей и получать более точные и надежные результаты. Эти стратегии особенно полезны для решения сложных задач, требующих аналитического мышления, последовательных рассуждений или высокой точности ответов.

**Для базовых техник промпт-инжиниринга** см. [[Prompt_Engineering/Prompt_Engineering_Best_Practices|Лучшие практики Prompt Engineering]].

---

## Shot Prompting

**Shot prompting** — это подход, при котором модели предоставляются примеры (shots), на основе которых она может обучиться в процессе ответа или руководствоваться ими при выполнении задачи. При такой структуре сначала передаются примеры, а в конце указываются входные данные, с которыми нужно работать так же, как в примерах.

### Типы Shot Prompting

1. **Zero-shot** — не предоставляется ни одного примера
2. **One-shot** — предоставляется один пример
3. **Few-shot** — предоставляется более одного примера (обычно 2-5)

### Zero-Shot Prompting

Zero-shot используется для решения простых заданий, и ответ модели основывается исключительно на данных, на которых она была обучена.

**Важно**: Если у модели нет данных после определенной даты (например, после 2023 года), ее ответ может содержать устаревшую информацию.

**Пример**:
```python
prompt = "Что такое дата инженерия?"
response = get_response(prompt)
```

**Когда использовать**:
- Простые вопросы общего характера
- Задачи, не требующие специфического формата ответа
- Модель уже обучена на достаточном количестве подобных примеров

### One-Shot Prompting

One-shot предоставляет модели **один пример**, из которого она может извлечь информацию о формате вывода или стиле ответа.

**Пример 1 — Формат вычислений**:
```python
prompt = """В: Сумма чисел 3, 5, и 6. О: 3+5+6=14
В: Сумма чисел 2, 4, и 7. О: """

print(get_response(prompt))
# Ожидаемый вывод: О: 2+4+7=13
```

**Пример 2 — Изменение стиля**:
```python
prompt = """В: Сумма чисел 3, 5, и 6. О: Сумма чисел 3, 5, и 6 равна 14.
В: Сумма чисел 2, 4, и 7. О: """

print(get_response(prompt))
# Ожидаемый вывод: О: Сумма чисел 2, 4, и 7 равна 13.
```

Как видно из примеров, изменение стиля в примере влияет на формат ответа модели.

### Few-Shot Prompting

Few-shot используется преимущественно в задачах **классификации и категоризации**. Предоставляется несколько примеров (обычно 3-5), которые демонстрируют модели логику классификации.

**Пример — Классификация настроений**:
```python
prompt = """
Текст: Сегодня отличная погода. Классификация: Позитивный
Текст: Я не люблю дождь. Классификация: Негативный
Текст: Мне нравится эта книга. Классификация: Позитивный
Текст: Этот фильм был ужасным. Классификация: Негативный
Текст: Мебель не большая. Классификация: Нейтральный
Текст: Выбор данных примеров просто ужасен. Классификация:
"""

print(get_response(prompt))
# Ожидаемый вывод: Негативный
```

### Few-Shot через диалог (User-Assistant Conversation)

Вместо передачи всех примеров в одном промпте, можно использовать структуру диалога с ролями `user` и `assistant`:

```python
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {'role': 'user', 'content': 'Сегодня отличная погода'},
        {'role': 'assistant', 'content': 'Позитивный'},
        {'role': 'user', 'content': 'Я не люблю дождь'},
        {'role': 'assistant', 'content': 'Негативный'},
        {'role': 'user', 'content': 'Мне нравится эта книга'},
        {'role': 'assistant', 'content': 'Позитивный'},
        {'role': 'user', 'content': 'Этот фильм был ужасным'},
        {'role': 'assistant', 'content': 'Негативный'},
        {'role': 'user', 'content': 'Мебель не большая'},
        {'role': 'assistant', 'content': 'Нейтральный'},
        {'role': 'user', 'content': 'Выбор данных примеров просто ужасен.'}
    ]
)
```

Этот подход особенно эффективен для создания классификаторов и систем с предсказуемым форматом ответов.

---

## Multi-Step Prompting

**Multi-step prompting** — это техника пошагового направления модели к достижению поставленной цели. Цель разбивается на шаги, и каждый шаг описывается в виде конкретного действия.

### Отличие от обычного промпта

**Без multi-step** (модель сама выбирает структуру):
```python
prompt = "Составь блог о путешествии"
```

Модель сама решает, что включить в блог, опираясь на свои внутренние данные.

**С multi-step** (явное указание шагов):
```python
prompt = """Составь блог о путешествии, следуя следующим шагам:
1. Расскажи про место назначения
2. Поделись личными приключениями, которые произошли в путешествии
3. Резюмируй путешествие"""
```

Модель следует четкой структуре, что обеспечивает предсказуемость и полноту результата.

### Применение в когнитивных задачах

Multi-step prompting полезен для проверки кода, анализа данных и других задач, требующих последовательных действий.

**Пример — Анализ кода**:

**Версия 1 — Простой запрос**:
```python
calculator = """
def add(a, b):
    return a + b
def subtract(a, b):
    return a - b
def multiply(a, b):
    return a * b
def divide(a, b):
    return a / b
"""

prompt = f"""Определи верно ли написан код обрамленный тройными обратными кавычками.
Ответь только да или нет.

```{calculator}```"""

# Вывод: Да
```

Ответ поверхностный — мы не знаем, учла ли модель деление на ноль.

**Версия 2 — Multi-step подход**:
```python
prompt = f"""Определи верно ли написан код обрамленный тройными обратными кавычками.
Проверку надо осуществить по следующим этапам:
1. Проверь корректность кода каждой функции
2. Проверь правильно ли обрабатывает функция деления ситуацию деления на ноль

```{calculator}```"""

# Вывод: Код содержит ошибку в функции деления, не обрабатывающей деление на ноль.
```

Multi-step промпт позволяет получить глубокий анализ с выявлением скрытых проблем.

### Когда использовать Multi-Step Prompting

- Написание структурированного контента (статьи, отчеты, посты)
- Анализ кода и данных
- Решение многоэтапных задач (планирование, исследование)
- Ситуации, когда важна последовательность выполнения действий

---

## Chain-of-Thought Prompting (Цепочка мыслей)

**Chain-of-Thought (CoT)** — это техника, при которой мы запрашиваем у модели **этапы мышления**, которые она выполняет при решении задачи. Это позволяет нам отследить логику модели и заблаговременно выявить ошибки в рассуждениях.

### Базовый пример

**Без Chain-of-Thought**:
```python
prompt = """В начале у тебя было 15 книг. В книжном магазине ты купил еще 8 книг.
Потом ты оставил 3 у друга и 2 у брата. Позже ты пошел в другой книжный магазин
и купил еще 5 книг. Сколько всего у тебя теперь книг? О: Ответ на задачу: """

# Вывод: 23
```

Мы получили только ответ, но не видим хода мыслей модели.

**С Chain-of-Thought**:
```python
prompt = """В начале у тебя было 15 книг. В книжном магазине ты купил еще 8 книг.
Потом ты оставил 3 у друга и 2 у брата. Позже ты пошел в другой книжный магазин
и купил еще 5 книг. Сколько всего у тебя теперь книг? О: Давай подумаем шаг за шагом."""

# Вывод:
# 1. Начальное количество книг: 15
# 2. Купил 8 книг: 15 + 8 = 23
# 3. Оставил 3 книги у друга: 23 - 3 = 20
# 4. Оставил 2 книги у брата: 20 - 2 = 18
# 5. Купил еще 5 книг: 18 + 5 = 23
# Ответ: 23 книги
```

Теперь мы видим пошаговую логику и можем проверить корректность каждого шага.

### Few-Shot + Chain-of-Thought

Можно комбинировать цепочку мыслей с few-shot подходом, чтобы показать модели пример логики решения.

**Пример — Проверка утверждения**:
```python
example = """
В: Сумма нечетных чисел в указанном наборе является четным числом. Набор: 9, 10, 13, 4, 2.
О: Складываем все нечетные числа из набора: 9 + 13 = 22. Утверждение верно.
"""

question = """
В: Сумма нечетных чисел в указанном наборе является четным числом. Набор: 15, 13, 82, 7.
О:
"""

prompt = example + question

# Вывод: Складываем все нечетные числа из набора: 15 + 13 + 7 = 35.
# Сумма равна нечетному числу, поэтому утверждение неверно.
```

### Ограничения Chain-of-Thought

**Главный недостаток**: Если хотя бы один этап рассуждений содержит ошибку, все последующие этапы также станут неверными (эффект домино).

**Решение**: Self-Consistency Prompting.

---

## Self-Consistency Prompting (Самосогласованные запросы)

**Self-Consistency** — это техника, при которой генерируются **несколько независимых цепочек мыслей** путем многократного запроса к модели. Финальный результат определяется как ответ, который встречался наибольшее количество раз.

### Принцип работы

1. Один и тот же вопрос отправляется модели несколько раз (обычно 3-5)
2. Для каждого запроса модель генерирует независимую цепочку рассуждений
3. Выбирается ответ, который появился чаще всего (консенсус)

### Реализация

**Метод 1 — Явное указание экспертов в промпте**:
```python
self_consistency_prompt = """Представь трех независимых экспертов, которые решают
одну и ту же задачу, но разными путями и рассуждениями. Окончательным ответом
будет являться то значение, которое выбрала большая часть экспертов. Решите задачу ниже:"""

problem = """Если на парковке есть 10 машин и еще 3 машины приехали. Половина от
первоначального количества машин уехали. Потом половина от текущего количества машин
приехали. Сколько машин теперь на парковке?"""

prompt = self_consistency_prompt + problem

# Вывод:
# Эксперт 1: 10 + 3 = 13, уехали 5 (половина от 10), 13 - 5 = 8, приехали 4 (половина от 8), 8 + 4 = 12
# Эксперт 2: 10 + 3 = 13, уехали 5, 13 - 5 = 8, приехали 4, 8 + 4 = 12
# Эксперт 3: 10 + 3 = 13, уехали 5, 13 - 5 = 8, приехали 4, 8 + 4 = 12
# Ответ: 12 (по мнению всех экспертов)
```

**Метод 2 — Множественные запросы программно**:
```python
def get_consensus_answer(prompt, num_attempts=5):
    """Генерирует несколько ответов и возвращает наиболее частый"""
    answers = []
    for _ in range(num_attempts):
        response = get_response(prompt)
        # Извлекаем числовой ответ из текста
        answer = extract_number(response)
        answers.append(answer)

    # Возвращаем наиболее частый ответ
    from collections import Counter
    most_common = Counter(answers).most_common(1)[0][0]
    return most_common
```

### Преимущества Self-Consistency

- **Повышение надежности**: снижает влияние случайных ошибок в рассуждениях
- **Выявление неоднозначности**: если нет консенсуса, задача может быть сформулирована неясно
- **Улучшение для сложных задач**: особенно эффективно для математических и логических задач

### Недостатки

- Увеличивает количество API-запросов (и, соответственно, стоимость)
- Требует больше времени для получения ответа
- Необходимо использовать достаточно высокий `temperature` (0.7-1.0) для получения разнообразных ответов

---

## Iterative Prompt Engineering and Refinement

**Итеративный промпт-инжиниринг** — это циклический процесс улучшения промпта через анализ результатов и внесение изменений.

### Цикл итеративной разработки

```
1. Создать промпт
    ↓
2. Отправить модели
    ↓
3. Проанализировать результат
    ↓
4. Выявить недостатки
    ↓
5. Улучшить промпт (добавить контекст, уточнить инструкции, изменить формат)
    ↓
6. Повторить процесс до достижения желаемого результата
```

### Примеры итеративного улучшения

#### Пример 1 — Формат вывода

**Итерация 1 — Плохой промпт**:
```python
bad_prompt = """Сгенерируй excel таблицу с колонками:
- Имя ученика
- Средняя оценка"""
```

**Проблема**: Модель не может создавать файлы Excel.

**Итерация 2 — Улучшенный промпт**:
```python
good_prompt = """Сгенерируй таблицу в формате markdown с колонками:
- Имя ученика
- Средняя оценка"""
```

**Результат**: Модель создаст Markdown-таблицу, которую легко скопировать в Excel.

#### Пример 2 — Добавление структуры

**Итерация 1 — Простой запрос**:
```python
prompt = f"""Проанализируй код обрамленный тройными обратными кавычками.
Также скажи на каком языке программирования написан код.
Результат должен быть одним предложением.

```{code}```"""
```

**Итерация 2 — Структурированный запрос**:
```python
prompt = f"""Проанализируй код обрамленный тройными обратными кавычками.
Для анализа используй следующую структуру:
- Описание: короткое описание в одно предложение
- Язык программирования: на каком языке программирования написан код
- Входные данные: какие входные параметры надо передать функции
- Выходные данные: какие выходные данные возвращает функция

```{code}```"""
```

Структурированный промпт обеспечивает полноту и предсказуемость ответа.

#### Пример 3 — Уточнение контекста (Few-Shot Refinement)

**Итерация 1 — Базовый Few-Shot**:
```python
prompt = """
- Ясная хорошая погода -> солнечно
- Сильный дождь с грозой -> дождливо
- Снегопад с морозом -> снежно
- Ветер перемен принес большим компаниям немного свежего воздуха ->
"""

# Вывод: ветрено (неверная интерпретация метафоры)
```

**Проблема**: Модель не поняла, что "ветер перемен" — это бизнес-метафора, а не погодное явление.

**Итерация 2 — Добавление ограничений и примера**:
```python
prompt = """
Анализируй только погодные условия. Если в предложении не идет речь о погоде,
классифицируй его как "неизвестно"

- Ясная хорошая погода -> солнечно
- Сильный дождь с грозой -> дождливо
- Штормовая политическая погода в стране -> неизвестно
- Ветер перемен принес большим компаниям глоток свежего воздуха ->
"""

# Вывод: неизвестно (правильная интерпретация)
```

### Когда применять итеративный подход

- Модель не понимает контекст задачи
- Формат ответа не соответствует ожиданиям
- Модель допускает систематические ошибки
- Требуется высокая точность результата
- Задача нестандартная или специфичная для вашей области

---

## Сравнение техник

| Техника | Когда использовать | Преимущества | Недостатки |
|---------|-------------------|--------------|------------|
| **Zero-Shot** | Простые задачи, общие вопросы | Быстро, не требует примеров | Менее предсказуемо, может быть неточно |
| **One-Shot** | Нужен конкретный формат ответа | Показывает желаемый стиль | Один пример может быть недостаточным |
| **Few-Shot** | Классификация, категоризация, специфичные форматы | Высокая точность, гибкость | Требует подготовки примеров, больше токенов |
| **Multi-Step** | Структурированные задачи, анализ, планирование | Предсказуемая последовательность | Требует явного описания шагов |
| **Chain-of-Thought** | Логические задачи, математика, анализ | Прозрачность логики, выявление ошибок | Ошибка на одном этапе влияет на все остальные |
| **Self-Consistency** | Критичные задачи, требующие высокой надежности | Повышение точности через консенсус | Больше запросов, выше стоимость и время |
| **Iterative** | Сложные задачи, нестандартные требования | Постепенное улучшение до идеала | Требует времени и многократных тестов |

---

## Комбинирование техник

Часто наилучшие результаты достигаются при комбинировании нескольких техник:

### Пример 1: Few-Shot + Chain-of-Thought
```python
prompt = """
Решай задачи, показывая пошаговые рассуждения.

Пример:
В: У Маши было 10 яблок. Она отдала 3 яблока Пете и купила еще 5. Сколько яблок у нее теперь?
О: Шаг 1: Начальное количество: 10
   Шаг 2: После того как отдала: 10 - 3 = 7
   Шаг 3: После покупки: 7 + 5 = 12
   Ответ: 12 яблок

В: У Коли было 15 конфет. Он съел 4 конфеты и купил еще 8. Сколько конфет у него теперь?
О:
"""
```

### Пример 2: Multi-Step + Iterative
```python
# Итерация 1
prompt_v1 = """Напиши статью о Python"""

# Итерация 2 (добавили шаги)
prompt_v2 = """Напиши статью о Python, следуя этим шагам:
1. Введение
2. Основные преимущества
3. Примеры использования"""

# Итерация 3 (уточнили детали)
prompt_v3 = """Напиши статью о Python для начинающих программистов, следуя этим шагам:
1. Введение (1 параграф): Что такое Python и почему он популярен
2. Основные преимущества (3-5 пунктов): Конкретные преимущества с кратким объяснением
3. Примеры использования (3 примера): Веб-разработка, data science, автоматизация
Объем: 300-400 слов, простой язык без сложных терминов."""
```

### Пример 3: Few-Shot + Self-Consistency
```python
prompt = """Представь 3 независимых экспертов-классификаторов.
Каждый классифицирует текст самостоятельно, опираясь на примеры.
Финальный ответ — тот, который выбрало большинство.

Примеры:
- "Отличная книга!" -> Позитивный
- "Ужасный сервис" -> Негативный
- "Неплохо, но можно лучше" -> Нейтральный

Классифицируй: "Это был интересный опыт, хотя и с некоторыми недостатками"
"""
```

---

## Практические рекомендации

### 1. Начинайте с простого
- Сначала попробуйте zero-shot
- Если результат неудовлетворительный, добавьте 1-2 примера (few-shot)
- Если нужна прозрачность логики, используйте chain-of-thought

### 2. Тестируйте на разных данных
- Обычные случаи (типичные входные данные)
- Граничные случаи (пустые данные, экстремальные значения)
- Некорректные данные (проверка обработки ошибок)

### 3. Документируйте успешные промпты
Создайте библиотеку промптов для типовых задач:
```python
PROMPT_TEMPLATES = {
    "classification_few_shot": """...""",
    "code_analysis_multistep": """...""",
    "math_problem_cot": """..."""
}
```

### 4. Используйте Self-Consistency осознанно
Применяйте только когда:
- Задача критична (финансовые расчеты, медицинские выводы)
- Модель показывает нестабильные результаты
- Бюджет позволяет множественные запросы

### 5. Комбинируйте с параметрами API
```python
# Для chain-of-thought и self-consistency
response = client.chat.completions.create(
    model="gpt-4",
    messages=[...],
    temperature=0.7,  # Баланс между детерминированностью и разнообразием
    max_tokens=1000,  # Достаточно для развернутых рассуждений
    top_p=0.9
)

# Для строгих задач (математика, код)
response = client.chat.completions.create(
    model="gpt-4",
    messages=[...],
    temperature=0.0,  # Максимальная детерминированность
    max_tokens=500
)
```

---

## Отличия между техниками

### Multi-Step vs Chain-of-Thought

| Аспект | Multi-Step | Chain-of-Thought |
|--------|------------|------------------|
| **Кто определяет шаги** | Вы (явно в промпте) | Модель (самостоятельно) |
| **Что показывает** | Что нужно сделать | Как модель думает |
| **Цель** | Структурировать выполнение | Проверить логику рассуждений |
| **Пример** | "Сделай задачу в 3 шага: 1... 2... 3..." | "Реши задачу шаг за шагом" |

### Few-Shot vs Chain-of-Thought

| Аспект | Few-Shot | Chain-of-Thought |
|--------|----------|------------------|
| **Что предоставляется** | Примеры входа/выхода | Запрос на объяснение мышления |
| **Цель** | Показать желаемый формат | Увидеть логику решения |
| **Обучает ли модель** | Да (на примерах) | Нет (просит объяснить) |
| **Можно комбинировать** | Да | Да (Few-Shot + CoT) |

---

## Связанные материалы

- [[Prompt_Engineering/Prompt_Engineering_Best_Practices|Лучшие практики Prompt Engineering]] - базовые техники промпт-инжиниринга
- [[OpenAI_API/Working_with_OpenAI_API_in_Python|Работа с OpenAI API в Python]] - практическая реализация промптов через API
- [[OpenAI_API/Chat_Roles_and_Multi_Turn_Conversations|Роли в чатах и многоэтапные диалоги]] - использование few-shot через user-assistant диалоги
- [[Python_for_AI/Python_Tools_for_AI_Engineers|Python инструменты для AI-инженеров]] - retry-логика и обработка ошибок для надежных API-вызовов
- [[Exercises/03_Prompt_Engineering_Exercise|Практическое задание №3]] - отработка базовых техник prompt engineering
- [[Exercises/04_Advanced_Prompt_Engineering_Strategies_Exercise|Практическое задание №4]] - комплексная отработка продвинутых стратегий (Shot Prompting, Chain-of-Thought, Self-Consistency, Multi-Step, итеративное улучшение)

---

## Дополнительные ресурсы

- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Engineering Techniques](https://docs.anthropic.com/claude/docs/prompt-engineering)
- [Chain-of-Thought Paper](https://arxiv.org/abs/2201.11903) — оригинальное исследование техники CoT
- [Self-Consistency Paper](https://arxiv.org/abs/2203.11171) — исследование самосогласованных запросов
- [Prompt Engineering Guide](https://www.promptingguide.ai/) — всеобъемлющее руководство по всем техникам

---

**Ключевой вывод**: Продвинутые техники промпт-инжиниринга позволяют решать сложные задачи через предоставление примеров (Few-Shot), пошаговых инструкций (Multi-Step), запрос логики рассуждений (Chain-of-Thought) и множественную проверку (Self-Consistency). Итеративное улучшение промптов — это нормальный и необходимый процесс для достижения оптимальных результатов.
