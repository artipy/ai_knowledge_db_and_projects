# Фаза разработки LLM-приложений (Development Phase)

Фаза разработки — это **циклический процесс** построения и улучшения приложения (цикл разработки). Он включает четыре ключевых этапа: Prompt Engineering → Chains & Agents → RAG & Fine-tuning → Testing.

Общий контекст жизненного цикла: [[Introduction_to_LLMOps_and_Ideation_Phase]]

---

## Prompt Engineering

Сердцем каждого LLM-приложения является промпт, который направляет модель к требуемому результату.

**Почему Prompt Engineering важен:**
- Понятные инструкции повышают точность и полезность ответов
- Хорошо сформированный промпт даёт больше контроля над выводом модели
- Помогает снизить предвзятость и галлюцинации

### Структура промпта

Типичный промпт состоит из четырёх блоков:

```
1. Инструкции для модели
2. Примеры или дополнительный контекст
3. Входные данные
4. Правила формата выходного ответа
```

### Ключевые параметры при тестировании промптов

| Параметр | Назначение |
|---|---|
| `temperature` | Управление случайностью ответа |
| `max_completion_tokens` | Ограничение длины ответа |

Дополнительно улучшить промпт помогает **обучение в контексте** (in-context learning) — добавление примеров входных и выходных данных прямо в промпт (Few-Shot подход).

### Управление промптами (Prompt Management)

После нахождения эффективного промпта важно вести его учёт:
- Сохранять сами промпты и полученные ответы
- Фиксировать модели и их настройки
- Использовать систему контроля версий для отслеживания изменений и выбора наилучшего варианта

### Шаблоны промптов

По мере накопления данных о работе модели переходят к **шаблонам** — структурам с переменными для подстановки данных. В Python реализуются через f-строки:

```python
template = f"Переведи следующий текст на английский:\n\n{user_text}"
```

Подробнее о техниках Prompt Engineering: [[Prompt_Engineering/Prompt_Engineering_Best_Practices]] и [[Prompt_Engineering/Advanced_Prompt_Engineering_Strategies]]

---

## Chains и Agents

### Chains (Цепочки)

**Chain** — последовательность шагов, которая принимает входные данные и преобразует их в выходные. Также известна как pipeline или flow.

**Пример**: приложение для подсчёта калорий еды:
1. Поиск похожей еды в базе данных
2. Комбинирование описания еды из базы с входным запросом
3. Передача запроса модели
4. Получение ответа от модели

**Зачем нужны Chains:**
- Позволяют создавать сложные приложения из простых шагов
- Обеспечивают модульный дизайн
- Улучшают масштабируемость и эффективность

### Agents (Агенты)

Когда цепочки недостаточно гибки, применяются агенты. LLM с агентами имеет доступ к набору **actions (инструментов)** и сама решает, какой инструмент применить в той или иной ситуации.

**Когда агенты предпочтительнее:**
- Слишком много возможных шагов в сценарии
- Оптимальное количество шагов заранее неизвестно
- Входные данные непредсказуемы

Каждое действие (action) может быть вызвано моделью **многократно** в зависимости от ситуации.

### Сравнение Chains и Agents

| Характеристика | Chains | Agents |
|---|---|---|
| Природа | Детерминированный | Адаптивный |
| Сложность | Низкая | Высокая |
| Гибкость | Низкая | Высокая |
| Риск | Ниже (предсказуемость) | Выше (адаптивность) |

**Вывод:** Chains всегда предсказуемы, но негибки для сложных сценариев. Agents гибки и решают сложные задачи, но результат непредсказуем.

---

## RAG vs Fine-tuning

### RAG (Retrieval-Augmented Generation)

**RAG** — стандартная структура LLM, объединяющая возможности модели с внешними фактическими знаниями. Состоит из трёх шагов:

```
Retrieve → Augment → Generate
```

1. **Retrieve** — извлечение релевантных документов из базы знаний
2. **Augment** — обогащение промпта данными из документов
3. **Generate** — генерация ответа с учётом дополнительного контекста

#### Векторные базы данных в RAG

Шаг Retrieve — самый сложный при работе с большими базами знаний. Решение — **векторные базы данных**:

1. Данные конвертируются в **embeddings** — цифровые векторные представления, фиксирующие смысл текста
2. Тексты со схожим смыслом имеют схожие embeddings
3. Embeddings создаются предобученными моделями
4. При запросе: embedding входного текста сравнивается с хранящимися в базе
5. Рассчитывается схожесть, извлекается наиболее близкий документ

### Fine-tuning

В отличие от RAG, который оперирует внешними данными, **fine-tuning настраивает веса модели**, расширяя её возможности для конкретной задачи (например, ответы на другом языке).

#### Два подхода к Fine-tuning

**1. Supervised Fine-tuning (наблюдаемый)**
- Форма transfer learning
- Требует размеченных данных: пары «входной запрос — ожидаемый ответ»
- Переобучает часть весов модели на новых данных

**2. Reinforcement Learning from Human Feedback (RLHF)**
- Обычно применяется после Supervised Fine-tuning
- Требует данных, размеченных людьми: рейтинги ответов, оценки «нравится/не нравится»
- Добавляет процесс вознаграждения модели и оптимизирует базовую LLM

### Сравнение RAG и Fine-tuning

| Критерий | RAG | Fine-tuning |
|---|---|---|
| Цель | Добавить фактические знания | Обучить новому поведению/стилю |
| Изменение модели | Нет | Да (веса модели изменяются) |
| Простота внедрения | Легче | Сложнее |
| Актуальность данных | Высокая (база обновляется) | Требует переобучения |
| Дополнительные компоненты | Нужны (векторная БД) | Не нужны |
| Риски | Инженерная сложность | Предвзятость, катастрофическая забывчивость |

**Катастрофическая забывчивость** — явление, при котором модель после fine-tuning забывает знания, полученные при первоначальном обучении.

---

## Testing (Тестирование)

Тестирование критически важно перед выпуском приложения, так как модели могут ошибаться. Тест-кейсы должны максимально приближаться к реальным сценариям использования.

### Методы тестирования

**1. Статистический метод**
Измеряет долю корректных ответов из общего числа — показывает, сколько ответов верно.

**2. LLM-as-a-Judge**
Другая LLM оценивает, насколько хорошо приложение соответствует ожиданиям. Один из самых распространённых подходов.

**3. Оценка на основе предыдущих результатов**
Модель корректирует оценку, основываясь на накопленных данных о предыдущих ответах.

**4. Категориальная характеристика ответов**
Ответы классифицируются по характеристикам (приемлемые / неприемлемые). Дополнительно оцениваются метрики производительности: скорость ответа и другие.

### Непрерывное тестирование

Тестирование настраивается как **цикличный процесс**: при каждом изменении промптов или модели тесты запускаются повторно. Успешное прохождение всех тестов — сигнал для перехода к фазе эксплуатации.

---

## Связанные темы

- [[Introduction_to_LLMOps_and_Ideation_Phase]] — предыдущая фаза: идеация, выбор данных и модели
- [[Prompt_Engineering/Prompt_Engineering_Best_Practices]] — базовые техники создания эффективных промптов
- [[Prompt_Engineering/Advanced_Prompt_Engineering_Strategies]] — Zero-Shot, Few-Shot, Chain-of-Thought, Self-Consistency
- [[Prompt_Engineering/Prompt_Engineering_for_Business_Applications]] — практическое применение промптов
- [[Hugging_Face/Building_Pipelines_with_Hugging_Face]] — Pipeline API как пример chain-архитектуры
- [[OpenAI_API/Chat_Roles_and_Multi_Turn_Conversations]] — управление контекстом в LLM-приложениях
