# Введение в OpenAI API

Эта заметка содержит базовое введение в работу с OpenAI API, объясняет основные концепции и демонстрирует простейший пример подключения к API и отправки запросов.

## Связанные заметки

- [[OpenAI_API/Working_with_OpenAI_API_in_Python|Работа с OpenAI API в Python]] - практические примеры использования API для различных задач обработки текста
- [[OpenAI_API/Chat_Roles_and_Multi_Turn_Conversations|Роли в чатах и многоэтапные диалоги]] - использование system, user и assistant ролей, создание диалогов с контекстом
- [[Exercises/01_OpenAI_API_Text_Processing_Exercise|Практическое задание №1]] - проверка усвоенных знаний по работе с OpenAI API

## Что такое API?

**API (Application Programming Interface)** - это интерфейс для взаимодействия между приложениями. В контексте работы с языковыми моделями, API используется как мессенджер, который передает сообщение системе (модели) и получает от нее ответ, содержащий данные или сервисы.

API выступает посредником между вашим приложением и сервисами провайдера (например, OpenAI), позволяя отправлять запросы и получать ответы в стандартизированном формате.

## Основные понятия

### Endpoints (конечные точки)

Для того чтобы подключиться к модели, используются **endpoints** - это URL-адреса, по которым ваше приложение отправляет запросы к API. Каждый endpoint отвечает за определенный тип операций (например, генерация текста, работа с изображениями и т.д.).

### API Key (ключ API)

Чтобы endpoint позволил нам получить доступ к сервису, используется **api_key** - уникальный ключ аутентификации. Этот ключ:
- Создается в личном кабинете провайдера (OpenAI, Hugging Face, OpenRouter и др.)
- Служит для идентификации пользователя и учета использования
- Должен храниться в безопасности и не публиковаться в открытом коде

## Установка и подключение

Для того чтобы подключиться к OpenAI API, необходимо установить соответствующую библиотеку:

```bash
pip install openai
```

Также для безопасной работы с API ключами рекомендуется использовать переменные окружения:

```bash
pip install python-dotenv
```

## Базовый пример работы с API

Вот простейший пример подключения к API и отправки запроса:

```python
from openai import OpenAI
from dotenv import load_dotenv
import os

# Загружаем переменные окружения из файла .env
load_dotenv()

# Для подключения используется api_key, созданный в личном кабинете OpenAI
# или у другого вендора (Hugging Face, OpenRouter и т.д.)
# Параметр base_url позволяет использовать совместимые с OpenAI API сервисы
client = OpenAI(
    api_key = os.getenv("GEMINI_TOKEN"),      # API ключ из переменных окружения
    base_url = os.getenv("BASE_URL")          # URL эндпоинта (опционально)
)

# Чтобы отправить запрос, используется метод chat.completions.create()
response = client.chat.completions.create(
    model=os.getenv("BASE_MODEL"),            # Имя модели для использования
    messages=[
        {"role": "user", "content": "Привет! Как дела?"}
    ]
)

# Чтобы получить текстовый ответ модели, нужно обратиться к полю 'choices' и 'message'
print(response.choices[0].message.content)
```

### Пример ответа:

```
Привет! У меня всё отлично, спасибо. Я всегда готов к общению и новым задачам.

А как твои дела? Как проходит день? Чем я могу тебе сегодня помочь?
```

## Структура запроса

Базовый запрос к API содержит следующие ключевые параметры:

- **`model`** - название модели, которую вы хотите использовать (например, `gpt-4o-mini`, `gpt-4o`)
- **`messages`** - список сообщений, формирующих диалог. Каждое сообщение представляет собой словарь с полями:
  - **`role`** - роль отправителя (`user` для пользователя, `assistant` для модели, `system` для системных инструкций)
  - **`content`** - текстовое содержимое сообщения

## Безопасное хранение API ключей

**Важно:** Никогда не храните API ключи непосредственно в коде!

Для безопасной работы используйте один из подходов:
1. **Переменные окружения** через файл `.env` (как в примере выше)
2. **Менеджеры секретов** (Vault, AWS Secrets Manager и т.д.)
3. **Переменные окружения системы**

Пример файла `.env`:
```
GEMINI_TOKEN=your-api-key-here
BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/
BASE_MODEL=gemini-2.0-flash-exp
```

## Совместимость с другими провайдерами

Библиотека OpenAI совместима не только с официальным API OpenAI, но и с другими провайдерами, которые поддерживают OpenAI-совместимый формат:

- **Google Gemini** (через OpenAI-совместимый интерфейс)
- **Hugging Face** (inference endpoints)
- **OpenRouter** (мультипровайдер)
- **LM Studio** (локальные модели)
- Многие другие провайдеры

Для этого достаточно указать соответствующий `base_url` и `api_key` провайдера.

## Следующие шаги

После освоения базового подключения к API, рекомендуется изучить:
- [[OpenAI_API/Working_with_OpenAI_API_in_Python|Практические примеры работы с API]] - редактирование, резюмирование, генерация текста
- [[OpenAI_API/Chat_Roles_and_Multi_Turn_Conversations|Роли в чатах и многоэтапные диалоги]] - система ролей, управление поведением модели, создание контекстных диалогов
- Управление параметрами генерации (temperature, max_tokens)
- Техники промптинга (few-shot, chain-of-thought)
- Управление стоимостью и токенами

---

*Эта заметка создана на основе практических примеров работы с OpenAI-совместимым API.*
